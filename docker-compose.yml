x-app-env: &app-env
  REDIS_URL: redis://redis:6379/0
  REDIS_QUEUE_KEY: jobs:queue
  REDIS_STATUS_KEY: jobs:status
  GENERATED_ROOT: /data/generated
  SERVER_READY_FILE: /models/.server_ready
  SERVER_BUILDING_FILE: /models/.server_building

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  app1: &app-service
    build:
      context: .
      dockerfile: Dockerfile.app
    environment:
      <<: *app-env
      APP_INSTANCE: app1
    volumes:
      - ./generated:/data/generated
      - ./models:/models:ro
    expose:
      - "5000"
    depends_on:
      - redis

  app2:
    <<: *app-service
    environment:
      <<: *app-env
      APP_INSTANCE: app2

  app3:
    <<: *app-service
    environment:
      <<: *app-env
      APP_INSTANCE: app3

  inference:
    build:
      context: .
      dockerfile: Dockerfile.inference
    environment:
      <<: *app-env
      LTX_MODEL_ID: /models/ltx-video-0.9.8-13b-distilled
      LTX_DEVICE: cuda
      LTX_NUM_FRAMES: "121"
      LTX_OUTPUT_FPS: "24"
      LTX_HEIGHT: "512"
      LTX_WIDTH: "768"
      LTX_INFERENCE_STEPS: "40"
      HF_HOME: /models/hf-cache
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    volumes:
      - ./generated:/data/generated
      - ./models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      - redis

  caddy:
    image: caddy:2
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
    ports:
      - "80:5000"
    depends_on:
      - app1
      - app2
      - app3
