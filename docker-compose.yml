x-app-env: &app-env
  REDIS_URL: redis://redis:6379/0
  REDIS_QUEUE_KEY: jobs:queue
  REDIS_STATUS_KEY: jobs:status
  GENERATED_ROOT: /data/generated
  MODEL_READY_FILE: /models/.model_ready
  MODEL_DOWNLOADING_FILE: /models/.model_downloading

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  app1: &app-service
    build:
      context: .
      dockerfile: Dockerfile.app
    environment:
      <<: *app-env
      APP_INSTANCE: app1
    volumes:
      - ./generated:/data/generated
      - ./models:/models:ro
    expose:
      - "5000"
    depends_on:
      - redis

  app2:
    <<: *app-service
    environment:
      <<: *app-env
      APP_INSTANCE: app2

  inference:
    build:
      context: .
      dockerfile: Dockerfile.inference
    environment:
      <<: *app-env
      LTX_MODEL_ID: /models/LTX-Video
      LTX_DEVICE: auto
      LTX_NUM_FRAMES: "121"
      LTX_OUTPUT_FPS: "24"
      LTX_HEIGHT: "512"
      LTX_WIDTH: "768"
      LTX_INFERENCE_STEPS: "40"
      HF_HOME: /models/hf-cache
      FAKE_INFERENCE: "1"
      FAKE_INFERENCE_SOURCE: /app/test.mp4
    volumes:
      - ./generated:/data/generated
      - ./models:/models
    depends_on:
      - redis

  caddy:
    image: caddy:2
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
    ports:
      - "5000:5000"
    depends_on:
      - app1
      - app2
